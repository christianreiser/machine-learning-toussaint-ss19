# Ridge Regression notes
## Regression
* fit function to data
* data: input x1, x2; output y
* param beta 
* features fi 
* Loss L(beta)

## Regularization
1. reduce overfitting -> imporove generalization
2. lower estimator variance
3. beta1 is not regularized by setting first element of eye to zero
4. MSE does not take regularization error into account
